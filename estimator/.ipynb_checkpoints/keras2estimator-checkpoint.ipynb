{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 通过 Keras 模型创建 Estimator\n",
    "TensorFlow 完全支持 TensorFlow Estimator，可以从新的和现有的 tf.keras 模型创建 Estimator。本教程包含了该过程完整且最为简短的示例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(16, activation='relu', input_shape=(4,)),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(3)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 131\n",
      "Trainable params: 131\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              optimizer='adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建 Input Function \n",
    "estimator train 的时候需要传入： input_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n",
      "Label: species\n"
     ]
    }
   ],
   "source": [
    "# CSV文件中列的顺序\n",
    "column_names = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species']\n",
    "\n",
    "feature_names = column_names[:-1]\n",
    "label_name = column_names[-1]\n",
    "\n",
    "print(\"Features: {}\".format(feature_names))\n",
    "print(\"Label: {}\".format(label_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pack_features_vector(features, labels):\n",
    "    \"\"\"\n",
    "    将一组特征列表（list）打包成一个特征向量\n",
    "    \"\"\"\n",
    "    features = tf.stack(list(features.values()), axis=1)\n",
    "    return features, labels\n",
    "\n",
    "def input_fn():\n",
    "    batch_size = 32\n",
    "    train_dataset_fp = './datasets/iris_training.csv'\n",
    "    train_dataset = tf.data.experimental.make_csv_dataset(train_dataset_fp,\n",
    "                                                          batch_size,\n",
    "                                                          column_names=column_names,\n",
    "                                                          label_name=label_name,\n",
    "                                                          num_epochs=1)\n",
    "    train_dataset = train_dataset.map(pack_features_vector)\n",
    "    return train_dataset.repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<RepeatDataset shapes: ((None, 4), (None,)), types: (tf.float32, tf.int32)>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_fn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## keras model trans estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using the Keras model provided.\n",
      "INFO:tensorflow:Using config: {'_model_dir': './keras2est_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "model_dir = './keras2est_model'\n",
    "pathlib.Path(model_dir).mkdir(parents=True, exist_ok=True) \n",
    "keras_estimator = tf.keras.estimator.model_to_estimator(keras_model=model, model_dir=model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Warm-starting with WarmStartSettings: WarmStartSettings(ckpt_to_initialize_from='./keras2est_model/keras/keras_model.ckpt', vars_to_warm_start='.*', var_name_to_vocab_info={}, var_name_to_prev_var_name={})\n",
      "INFO:tensorflow:Warm-starting from: ./keras2est_model/keras/keras_model.ckpt\n",
      "INFO:tensorflow:Warm-starting variables only in TRAINABLE_VARIABLES.\n",
      "INFO:tensorflow:Warm-started 4 variables.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into ./keras2est_model/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 1.4627235, step = 0\n",
      "INFO:tensorflow:global_step/sec: 705.129\n",
      "INFO:tensorflow:loss = 0.6269758, step = 100 (0.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 1226.5\n",
      "INFO:tensorflow:loss = 0.5394884, step = 200 (0.082 sec)\n",
      "INFO:tensorflow:global_step/sec: 1225.36\n",
      "INFO:tensorflow:loss = 0.47250545, step = 300 (0.081 sec)\n",
      "INFO:tensorflow:global_step/sec: 1122.52\n",
      "INFO:tensorflow:loss = 0.469547, step = 400 (0.089 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 500...\n",
      "INFO:tensorflow:Saving checkpoints for 500 into ./keras2est_model/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 500...\n",
      "INFO:tensorflow:Loss for final step: 0.3640392.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From /Users/Shared/miniconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_v1.py:2048: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-12-05T15:38:39Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./keras2est_model/model.ckpt-500\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [1/10]\n",
      "INFO:tensorflow:Evaluation [2/10]\n",
      "INFO:tensorflow:Evaluation [3/10]\n",
      "INFO:tensorflow:Evaluation [4/10]\n",
      "INFO:tensorflow:Evaluation [5/10]\n",
      "INFO:tensorflow:Evaluation [6/10]\n",
      "INFO:tensorflow:Evaluation [7/10]\n",
      "INFO:tensorflow:Evaluation [8/10]\n",
      "INFO:tensorflow:Evaluation [9/10]\n",
      "INFO:tensorflow:Evaluation [10/10]\n",
      "INFO:tensorflow:Inference Time : 0.15381s\n",
      "INFO:tensorflow:Finished evaluation at 2020-12-05-15:38:39\n",
      "INFO:tensorflow:Saving dict for global step 500: global_step = 500, loss = 0.31997377\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 500: ./keras2est_model/model.ckpt-500\n",
      "Eval result: {'loss': 0.31997377, 'global_step': 500}\n"
     ]
    }
   ],
   "source": [
    "keras_estimator.train(input_fn=input_fn, steps=500)\n",
    "eval_result = keras_estimator.evaluate(input_fn=input_fn, steps=10)\n",
    "print('Eval result: {}'.format(eval_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
