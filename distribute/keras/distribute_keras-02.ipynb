{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 准备数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define reader \n",
    "def load_mnist(path, prefix='train'):\n",
    "    import os\n",
    "    import gzip\n",
    "    import numpy as np\n",
    "\n",
    "    \"\"\"Load MNIST data from `path`\"\"\"\n",
    "    labels_path = os.path.join(path,\n",
    "                               '%s-labels-idx1-ubyte.gz'\n",
    "                               % prefix)\n",
    "    images_path = os.path.join(path,\n",
    "                               '%s-images-idx3-ubyte.gz'\n",
    "                               % prefix)\n",
    "\n",
    "    with gzip.open(labels_path, 'rb') as lbpath:\n",
    "        labels = np.frombuffer(lbpath.read(), dtype=np.uint8,\n",
    "                               offset=8)\n",
    "\n",
    "    with gzip.open(images_path, 'rb') as imgpath:\n",
    "        images = np.frombuffer(imgpath.read(), dtype=np.uint8,\n",
    "                               offset=16).reshape(len(labels), 784)\n",
    "\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_images shape: (60000, 784), train_labels shape: (60000,)\n",
      "test_images shape: (10000, 784), test_labels shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "# 读取本地训练数据, 并查看数据的 shape\n",
    "data_path='../classification/cv/datasets/fashion'\n",
    "\n",
    "train_images, train_labels = load_mnist(data_path, prefix='train')\n",
    "test_images, test_labels = load_mnist(data_path, prefix='t10k')\n",
    "print(\"train_images shape: {}, train_labels shape: {}\".format(train_images.shape, train_labels.shape))\n",
    "print(\"test_images shape: {}, test_labels shape: {}\".format(test_images.shape, test_labels.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构建 DataSets （Numpy -> Datasets）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset shapes: ((784,), ()), types: (tf.uint8, tf.uint8)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "train_datasets = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "train_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对标签 0-9 的数字做映射\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 10000\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# 将 MNIST 数据从 (0, 255] 缩放到 (0., 1.]\n",
    "def scale(image, label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image /= 255\n",
    "    return image, label\n",
    "    \n",
    "# (784,) --> (28, 28, 1)\n",
    "def reshape(image, label):\n",
    "    image = tf.reshape(image, [28, 28, 1])\n",
    "    return image, label\n",
    "\n",
    "local_train_datasets = train_datasets.map(reshape).map(scale).cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((None, 28, 28, 1), (None,)), types: (tf.float32, tf.uint8)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_train_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "938"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(local_train_datasets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试单节点的 trainning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建网络模型\n",
    "def build_and_compile_cnn_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(28, 28, 1)),\n",
    "        tf.keras.layers.MaxPooling2D(),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(10)\n",
    "    ])\n",
    "    model.compile(\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        optimizer=tf.keras.optimizers.SGD(learning_rate=0.001),\n",
    "        metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 执行训练\n",
    "single_worker_model = build_and_compile_cnn_model()\n",
    "single_worker_model.fit(x=train_datasets, epochs=3, steps_per_epoch=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 多 worker 模式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 配置 TF_CONFIG ENV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"cluster\": {\"worker\": [\"localhost:2222\", \"localhost:2223\"]}, \"task\": {\"type\": \"worker\", \"index\": 1}}'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, json\n",
    "os.environ['TF_CONFIG'] = json.dumps({\n",
    "    'cluster': {\n",
    "        'worker': [\"localhost:2222\", \"localhost:2223\"]\n",
    "    },\n",
    "    'task': {'type': 'worker', 'index': 1}\n",
    "})\n",
    "os.getenv('TF_CONFIG')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用 MultiWorkerMirroredStrategy 训练模型\n",
    "`MultiWorkerMirroredStrategy` 通过 `CollectiveCommunication` 参数提供多个实现。`RING` 使用 gRPC 作为跨主机通信层实现基于环的集合。`NCCL` 使用 Nvidia 的 `NCCL` 来实现集体。 `AUTO` 将选择推迟到运行时。 集体实现的最佳选择取决于GPU的数量和种类以及群集中的网络互连。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Enabled multi-worker collective ops with available devices: ['/job:worker/replica:0/task:1/device:CPU:0', '/job:worker/replica:0/task:1/device:XLA_CPU:0']\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:worker/task:1',)\n",
      "INFO:tensorflow:MultiWorkerMirroredStrategy with cluster_spec = {'worker': ['localhost:2222', 'localhost:2223']}, task_type = 'worker', task_id = 1, num_workers = 2, local_devices = ('/job:worker/task:1',), communication = CollectiveCommunication.AUTO\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# MultiWorkerMirroredStrategy.__init__() 会使用到 TF_CONFIG 初始化，建立集群通信\n",
    "strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running Distribute Coordinator with mode = 'independent_worker', cluster_spec = {'worker': ['localhost:2222', 'localhost:2223']}, task_type = 'worker', task_id = 1, environment = None, rpc_layer = 'grpc'\n",
      "WARNING:tensorflow:`eval_fn` is not passed in. The `worker_fn` will be used if an \"evaluator\" task exists in the cluster.\n",
      "WARNING:tensorflow:`eval_strategy` is not passed in. No distribution strategy will be used for evaluation.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:worker/task:1',)\n",
      "INFO:tensorflow:MultiWorkerMirroredStrategy with cluster_spec = {'worker': ['localhost:2222', 'localhost:2223']}, task_type = 'worker', task_id = 1, num_workers = 2, local_devices = ('/job:worker/task:1',), communication = CollectiveCommunication.AUTO\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:worker/task:1',)\n",
      "INFO:tensorflow:MultiWorkerMirroredStrategy with cluster_spec = {'worker': ['localhost:2222', 'localhost:2223']}, task_type = 'worker', task_id = 1, num_workers = 2, local_devices = ('/job:worker/task:1',), communication = CollectiveCommunication.AUTO\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:From /opt/conda/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/data/ops/multi_device_iterator_ops.py:601: get_next_as_optional (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Iterator.get_next_as_optional()` instead.\n",
      "INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 1, group_size = 2, communication_hint = AUTO, num_packs = 1\n",
      "INFO:tensorflow:Collective batch_all_reduce: 6 all-reduces, num_devices = 1, group_size = 2, communication_hint = AUTO, num_packs = 1\n",
      "INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 1, group_size = 2, communication_hint = AUTO, num_packs = 1\n",
      "INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 1, group_size = 2, communication_hint = AUTO, num_packs = 1\n",
      "INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 1, group_size = 2, communication_hint = AUTO, num_packs = 1\n",
      "INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 1, group_size = 2, communication_hint = AUTO, num_packs = 1\n",
      "INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 1, group_size = 2, communication_hint = AUTO, num_packs = 1\n",
      "INFO:tensorflow:Collective batch_all_reduce: 6 all-reduces, num_devices = 1, group_size = 2, communication_hint = AUTO, num_packs = 1\n",
      "INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 1, group_size = 2, communication_hint = AUTO, num_packs = 1\n",
      "INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 1, group_size = 2, communication_hint = AUTO, num_packs = 1\n",
      "INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 1, group_size = 2, communication_hint = AUTO, num_packs = 1\n",
      "INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 1, group_size = 2, communication_hint = AUTO, num_packs = 1\n",
      "19/20 [===========================>..] - ETA: 0s - loss: 2.3095 - accuracy: 0.1702WARNING:tensorflow:From /opt/conda/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /opt/conda/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: ./workertemp_1/keras-ckpt/assets\n",
      "20/20 [==============================] - 2s 84ms/step - loss: 2.3080 - accuracy: 0.1742\n",
      "Epoch 2/20\n",
      "19/20 [===========================>..] - ETA: 0s - loss: 2.2813 - accuracy: 0.2126INFO:tensorflow:Assets written to: ./workertemp_1/keras-ckpt/assets\n",
      "20/20 [==============================] - 2s 77ms/step - loss: 2.2809 - accuracy: 0.2113\n",
      "Epoch 3/20\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.2523 - accuracy: 0.2258INFO:tensorflow:Assets written to: ./workertemp_1/keras-ckpt/assets\n",
      "20/20 [==============================] - 2s 78ms/step - loss: 2.2523 - accuracy: 0.2258\n",
      "Epoch 4/20\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.2360 - accuracy: 0.2449INFO:tensorflow:Assets written to: ./workertemp_1/keras-ckpt/assets\n",
      "20/20 [==============================] - 2s 89ms/step - loss: 2.2360 - accuracy: 0.2449\n",
      "Epoch 5/20\n",
      "19/20 [===========================>..] - ETA: 0s - loss: 2.2153 - accuracy: 0.2508INFO:tensorflow:Assets written to: ./workertemp_1/keras-ckpt/assets\n",
      "20/20 [==============================] - 2s 87ms/step - loss: 2.2143 - accuracy: 0.2488\n",
      "Epoch 6/20\n",
      "19/20 [===========================>..] - ETA: 0s - loss: 2.2011 - accuracy: 0.2500INFO:tensorflow:Assets written to: ./workertemp_1/keras-ckpt/assets\n",
      "20/20 [==============================] - 2s 76ms/step - loss: 2.2000 - accuracy: 0.2551\n",
      "Epoch 7/20\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.1694 - accuracy: 0.2848INFO:tensorflow:Assets written to: ./workertemp_1/keras-ckpt/assets\n",
      "20/20 [==============================] - 2s 87ms/step - loss: 2.1694 - accuracy: 0.2848\n",
      "Epoch 8/20\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.1569 - accuracy: 0.2789INFO:tensorflow:Assets written to: ./workertemp_1/keras-ckpt/assets\n",
      "20/20 [==============================] - 2s 91ms/step - loss: 2.1569 - accuracy: 0.2789\n",
      "Epoch 9/20\n",
      "19/20 [===========================>..] - ETA: 0s - loss: 2.1423 - accuracy: 0.2870INFO:tensorflow:Assets written to: ./workertemp_1/keras-ckpt/assets\n",
      "20/20 [==============================] - 2s 91ms/step - loss: 2.1415 - accuracy: 0.2898\n",
      "Epoch 10/20\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.1165 - accuracy: 0.3195INFO:tensorflow:Assets written to: ./workertemp_1/keras-ckpt/assets\n",
      "20/20 [==============================] - 2s 90ms/step - loss: 2.1165 - accuracy: 0.3195\n",
      "Epoch 11/20\n",
      "19/20 [===========================>..] - ETA: 0s - loss: 2.1037 - accuracy: 0.3483INFO:tensorflow:Assets written to: ./workertemp_1/keras-ckpt/assets\n",
      "20/20 [==============================] - 2s 98ms/step - loss: 2.1039 - accuracy: 0.3484\n",
      "Epoch 12/20\n",
      "19/20 [===========================>..] - ETA: 0s - loss: 2.0752 - accuracy: 0.3828INFO:tensorflow:Assets written to: ./workertemp_1/keras-ckpt/assets\n",
      "20/20 [==============================] - 2s 80ms/step - loss: 2.0757 - accuracy: 0.3836\n",
      "Epoch 13/20\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.0597 - accuracy: 0.4023INFO:tensorflow:Assets written to: ./workertemp_1/keras-ckpt/assets\n",
      "20/20 [==============================] - 2s 76ms/step - loss: 2.0597 - accuracy: 0.4023\n",
      "Epoch 14/20\n",
      "19/20 [===========================>..] - ETA: 0s - loss: 2.0308 - accuracy: 0.4552INFO:tensorflow:Assets written to: ./workertemp_1/keras-ckpt/assets\n",
      "20/20 [==============================] - 2s 78ms/step - loss: 2.0283 - accuracy: 0.4590\n",
      "Epoch 15/20\n",
      "20/20 [==============================] - ETA: 0s - loss: 2.0100 - accuracy: 0.4852INFO:tensorflow:Assets written to: ./workertemp_1/keras-ckpt/assets\n",
      "20/20 [==============================] - 2s 80ms/step - loss: 2.0100 - accuracy: 0.4852\n",
      "Epoch 16/20\n",
      "19/20 [===========================>..] - ETA: 0s - loss: 1.9915 - accuracy: 0.4893INFO:tensorflow:Assets written to: ./workertemp_1/keras-ckpt/assets\n",
      "20/20 [==============================] - 1s 74ms/step - loss: 1.9925 - accuracy: 0.4836\n",
      "Epoch 17/20\n",
      "20/20 [==============================] - ETA: 0s - loss: 1.9674 - accuracy: 0.5086INFO:tensorflow:Assets written to: ./workertemp_1/keras-ckpt/assets\n",
      "20/20 [==============================] - 2s 90ms/step - loss: 1.9674 - accuracy: 0.5086\n",
      "Epoch 18/20\n",
      "20/20 [==============================] - ETA: 0s - loss: 1.9366 - accuracy: 0.5160INFO:tensorflow:Assets written to: ./workertemp_1/keras-ckpt/assets\n",
      "20/20 [==============================] - 2s 78ms/step - loss: 1.9366 - accuracy: 0.5160\n",
      "Epoch 19/20\n",
      "19/20 [===========================>..] - ETA: 0s - loss: 1.9179 - accuracy: 0.5214INFO:tensorflow:Assets written to: ./workertemp_1/keras-ckpt/assets\n",
      "20/20 [==============================] - 2s 76ms/step - loss: 1.9162 - accuracy: 0.5203\n",
      "Epoch 20/20\n",
      "20/20 [==============================] - ETA: 0s - loss: 1.8924 - accuracy: 0.5465INFO:tensorflow:Assets written to: ./workertemp_1/keras-ckpt/assets\n",
      "20/20 [==============================] - 2s 76ms/step - loss: 1.8924 - accuracy: 0.5465\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f0ac052dcd0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_WORKERS = 2\n",
    "# 由于 `tf.data.Dataset.batch` 需要全局的批处理大小，\n",
    "# 因此此处的批处理大小按 worker 数量增加。\n",
    "# 以前我们使用 64，现在变成 128\n",
    "GLOBAL_BATCH_SIZE = 64 * NUM_WORKERS\n",
    "\n",
    "# 创建数据集需要在 MultiWorkerMirroredStrategy 对象实例化后。\n",
    "dist_train_datasets = train_datasets.map(reshape).map(scale).cache().shuffle(BUFFER_SIZE).batch(GLOBAL_BATCH_SIZE)\n",
    "\n",
    "# 设置 checkpoint 回调. 该 path 一般为共享存储，保证所有的 worker 都能访问\n",
    "callbacks = [tf.keras.callbacks.ModelCheckpoint(filepath='./keras-ckpt')]\n",
    "with strategy.scope():\n",
    "  # 模型的建立/编译需要在 `strategy.scope()` 内部。\n",
    "  multi_worker_model = build_and_compile_cnn_model()\n",
    "\n",
    "# Keras 的 `model.fit()` 以特定的时期数和每时期的步数训练模型。\n",
    "# 注意此处的数量仅用于演示目的，并不足以产生高质量的模型。\n",
    "multi_worker_model.fit(x=dist_train_datasets, \n",
    "                       epochs=20, \n",
    "                       steps_per_epoch=20,\n",
    "                       callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
